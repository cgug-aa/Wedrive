{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU 모델 성능 평가\n",
    "사용 데이터: od_uuid/2023/00c02071a7d249b8b528230e9d63ad1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import geopy.distance\n",
    "import string\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define a function to convert numbers into corresponding letter labels\n",
    "def num_to_letter(num):\n",
    "    '''\n",
    "    num         : number that we have to convert\n",
    "    '''\n",
    "    return string.ascii_uppercase[num]\n",
    "\n",
    "def generate_initial_grids():\n",
    "        \"\"\"초기 그리드 생성\"\"\"\n",
    "        south, west, north, east = south_korea_bounds\n",
    "        lat_step = (north - south) / grid_size\n",
    "        lon_step = (east - west) / grid_size\n",
    "        grid_queue = []\n",
    "\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                grid_south = south + i * lat_step\n",
    "                grid_north = south + (i + 1) * lat_step\n",
    "                grid_west = west + j * lon_step\n",
    "                grid_east = west + (j + 1) * lon_step\n",
    "                grid_queue.append((grid_south, grid_west, grid_north, grid_east, \n",
    "                                   num_to_letter(i) + num_to_letter(j)))\n",
    "\n",
    "        return grid_queue\n",
    "\n",
    "# Create a function to get the grid label of the coordinate point\n",
    "def get_grid_label(lat, lng, final_grids):\n",
    "    '''\n",
    "    lat         : latitude\n",
    "    lng         : longitude\n",
    "    final_grids : all cells and their minimum/maximum latitude/longitude\n",
    "    '''\n",
    "    for south, west, north, east, grid_label in final_grids:\n",
    "        if south <= lat <= north and west <= lng <= east:\n",
    "            return grid_label\n",
    "    return None\n",
    "\n",
    "def is_path_in_grid(south, west, north, east, path_points):\n",
    "        \"\"\"경로가 그리드 안에 있는지 확인\"\"\"\n",
    "        return any(south <= lat <= north and west <= lng <= east for lat, lng in path_points)\n",
    "\n",
    "def subdivide_grids(grid_queue, path_points):\n",
    "    \"\"\"그리드 분할\"\"\"\n",
    "    final_grids = []\n",
    "\n",
    "    while grid_queue:\n",
    "        south, west, north, east, grid_label = grid_queue.pop(0)\n",
    "        grid_size_km = min(geopy.distance.distance((south, west), (south, east)).km,\n",
    "                           geopy.distance.distance((south, west), (north, west)).km)\n",
    "            \n",
    "        if grid_size_km > min_size_km and is_path_in_grid(south, west, north, east, path_points):\n",
    "            mid_lat = (south + north) / 2\n",
    "            mid_lon = (west + east) / 2\n",
    "            grid_queue.append((south, west, mid_lat, mid_lon, grid_label + 'C'))\n",
    "            grid_queue.append((mid_lat, west, north, mid_lon, grid_label + 'A'))\n",
    "            grid_queue.append((south, mid_lon, mid_lat, east, grid_label + 'D'))\n",
    "            grid_queue.append((mid_lat, mid_lon, north, east, grid_label + 'B'))\n",
    "        else:\n",
    "            final_grids.append((south, west, north, east, grid_label))\n",
    "\n",
    "    return final_grids\n",
    "\n",
    "# Approximate border coordinates of South Korea\n",
    "south_korea_bounds = [33.10, 124.57, 38.60, 131]\n",
    "min_size_km = 0.76\n",
    "grid_size = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_grid</th>\n",
       "      <th>end_grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEACAADB</td>\n",
       "      <td>EGCADDDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EGCADDDC</td>\n",
       "      <td>GEACAADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEACAADA</td>\n",
       "      <td>GFACDBDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GFACDBDA</td>\n",
       "      <td>GFAADCDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GFAADCDC</td>\n",
       "      <td>GFACDCBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>GFACBABC</td>\n",
       "      <td>GFCADABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>GFCADABA</td>\n",
       "      <td>GECDBACA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>GECDBACA</td>\n",
       "      <td>GECCDDAB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>GECDCACC</td>\n",
       "      <td>GDDDDDAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>GDDDDDAB</td>\n",
       "      <td>GFCABACD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2609 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start_grid  end_grid\n",
       "0      GEACAADB  EGCADDDC\n",
       "1      EGCADDDC  GEACAADA\n",
       "2      GEACAADA  GFACDBDA\n",
       "3      GFACDBDA  GFAADCDC\n",
       "4      GFAADCDC  GFACDCBA\n",
       "...         ...       ...\n",
       "2604   GFACBABC  GFCADABA\n",
       "2605   GFCADABA  GECDBACA\n",
       "2606   GECDBACA  GECCDDAB\n",
       "2607   GECDCACC  GDDDDDAA\n",
       "2608   GDDDDDAB  GFCABACD\n",
       "\n",
       "[2609 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터셋 로드\n",
    "#os.chdir('../')\n",
    "data_path=os.getcwd()+'/data/od_uuid/2023'\n",
    "\n",
    "#데이터셋 칼럼명 추가\n",
    "column_name=['id','start_time','end_time','start_lat','start_lng','end_lat','end_lng','?1','?2','?3']\n",
    "\n",
    "raw_data=pd.read_csv(data_path+'/00c02071a7d249b8b528230e9d63ad1d.csv')\n",
    "data=raw_data.values.tolist()\n",
    "dataframe=pd.DataFrame(data, columns=column_name)\n",
    "\n",
    "#전체데이터 그리드 생성\n",
    "start_points=dataframe[['start_lat','start_lng']].values.tolist()\n",
    "start_grid_queue = generate_initial_grids()\n",
    "start_final_grids = subdivide_grids(start_grid_queue, start_points)\n",
    "\n",
    "end_points=dataframe[['end_lat','end_lng']].values.tolist()\n",
    "end_grid_queue = generate_initial_grids()\n",
    "end_final_grids = subdivide_grids(end_grid_queue, end_points)\n",
    "\n",
    "dataframe['start_grid']=dataframe.apply(lambda row: get_grid_label(row['start_lat'], row['start_lng'], start_final_grids), axis=1)\n",
    "dataframe['end_grid']=dataframe.apply(lambda row: get_grid_label(row['end_lat'], row['end_lng'], end_final_grids), axis=1)\n",
    "dataframe=dataframe[['start_grid', 'end_grid']]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 출력 데이터를 토크나이저로 변환\n",
    "tokenizer = Tokenizer(char_level=True)  # 문자 단위 토크나이저\n",
    "tokenizer.fit_on_texts(dataframe['start_grid'] + dataframe['end_grid'])  # 입력과 출력 데이터 모두에 적용\n",
    "\n",
    "# 문자열 -> 정수 시퀀스 변환\n",
    "input_sequences = tokenizer.texts_to_sequences(dataframe['start_grid'])\n",
    "output_sequences = tokenizer.texts_to_sequences(dataframe['end_grid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "num_classes = len(tokenizer.word_index) + 1  # 토큰 개수 +1 (0은 패딩에 사용)\n",
    "y_sequences = np.array([to_categorical(seq, num_classes=num_classes) for seq in output_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련/테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.array(input_sequences), y_sequences, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11\\anaconda3\\envs\\wedrive\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=8),  # 임베딩 레이어\n",
    "    Bidirectional(GRU(128, return_sequences=True)),  # GRU 레이어\n",
    "    Bidirectional(GRU(64, return_sequences=True)),  # GRU 레이어\n",
    "    Bidirectional(GRU(32, return_sequences=True)),  # GRU 레이어\n",
    "    TimeDistributed(Dense(num_classes, activation='softmax'))\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - accuracy: 0.3832 - loss: 0.0663 - val_accuracy: 0.5087 - val_loss: 0.0563\n",
      "Epoch 2/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5167 - loss: 0.0560 - val_accuracy: 0.5493 - val_loss: 0.0537\n",
      "Epoch 3/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5741 - loss: 0.0515 - val_accuracy: 0.5577 - val_loss: 0.0534\n",
      "Epoch 4/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.5955 - loss: 0.0496 - val_accuracy: 0.5652 - val_loss: 0.0512\n",
      "Epoch 5/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6018 - loss: 0.0492 - val_accuracy: 0.5697 - val_loss: 0.0519\n",
      "Epoch 6/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6347 - loss: 0.0462 - val_accuracy: 0.5700 - val_loss: 0.0506\n",
      "Epoch 7/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6381 - loss: 0.0455 - val_accuracy: 0.5763 - val_loss: 0.0505\n",
      "Epoch 8/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.6366 - loss: 0.0458 - val_accuracy: 0.5676 - val_loss: 0.0507\n",
      "Epoch 9/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.6458 - loss: 0.0447 - val_accuracy: 0.5775 - val_loss: 0.0502\n",
      "Epoch 10/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.6395 - loss: 0.0450 - val_accuracy: 0.5786 - val_loss: 0.0503\n",
      "Epoch 11/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6337 - loss: 0.0452 - val_accuracy: 0.5763 - val_loss: 0.0514\n",
      "Epoch 12/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6503 - loss: 0.0443 - val_accuracy: 0.5712 - val_loss: 0.0512\n",
      "Epoch 13/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6702 - loss: 0.0424 - val_accuracy: 0.5733 - val_loss: 0.0505\n",
      "Epoch 14/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6642 - loss: 0.0427 - val_accuracy: 0.5807 - val_loss: 0.0502\n",
      "Epoch 15/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6534 - loss: 0.0435 - val_accuracy: 0.5706 - val_loss: 0.0514\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6105 - loss: 0.0476\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step \n",
      "----------------------------------------------\n",
      "Precision: 0.5424\n",
      "Recall: 0.5123\n",
      "F1-Score: 0.5203\n",
      "테스트 정확도: 0.6151819825172424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11\\anaconda3\\envs\\wedrive\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=15, validation_split=0.2, batch_size=4)\n",
    "\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Precision, Recall, F1-Score 계산\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# One-Hot Encoded -> 정수 인코딩으로 변환\n",
    "y_test_flat = np.argmax(y_test, axis=-1).flatten()\n",
    "y_pred_flat = np.argmax(y_pred, axis=-1).flatten()\n",
    "precision = precision_score(y_test_flat, y_pred_flat, average=\"macro\")\n",
    "recall = recall_score(y_test_flat, y_pred_flat, average=\"macro\")\n",
    "f1 = f1_score(y_test_flat, y_pred_flat, average=\"macro\")\n",
    "\n",
    "print('----------------------------------------------')\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f'테스트 정확도: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "입력 텍스트: GFAADCDC\n",
      "예측된 텍스트: GFACDCDA\n"
     ]
    }
   ],
   "source": [
    "# 예측 수행\n",
    "example_text = 'GFAADCDC'\n",
    "example_sequence = tokenizer.texts_to_sequences([example_text])[0]\n",
    "example_sequence = np.array([example_sequence])  # 모델 입력 형태로 변환\n",
    "\n",
    "# 예측 결과\n",
    "predictions = model.predict(example_sequence)\n",
    "predicted_tokens = np.argmax(predictions[0], axis=1)\n",
    "predicted_text = ''.join([tokenizer.index_word[token] for token in predicted_tokens])\n",
    "predicted_text=predicted_text.upper()\n",
    "print(f\"입력 텍스트: {example_text}\")\n",
    "print(f\"예측된 텍스트: {predicted_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|index|start_grid|end_grid|\n",
    "|---|---|---|\n",
    "|0|GEACAADB|EGCADDDC|\n",
    "|1|EGCADDDC|GEACAADA|\n",
    "|2|GEACAADA|GFACDBDA|\n",
    "|3|GFACDBDA|GFAADCDC|\n",
    "|4|GFAADCDC|GFACDCBA|\n",
    "|...|...|...|\n",
    "|2604|GFACBABC|GFCADABA|\n",
    "|2605|GFCADABA|GECDBACA|\n",
    "|2606|GECDBACA|GECCDDAB|\n",
    "|2607|GECDCACC|GDDDDDAA|\n",
    "|2608|GDDDDDAB|GFCABACD|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wedrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
