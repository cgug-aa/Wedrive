{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM 모델 성능 평가\n",
    "사용 데이터: od_uuid/2023/00c02071a7d249b8b528230e9d63ad1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import geopy.distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define a function to convert numbers into corresponding letter labels\n",
    "def num_to_letter(num):\n",
    "    '''\n",
    "    num         : number that we have to convert\n",
    "    '''\n",
    "    return string.ascii_uppercase[num]\n",
    "\n",
    "def generate_initial_grids():\n",
    "        \"\"\"초기 그리드 생성\"\"\"\n",
    "        south, west, north, east = south_korea_bounds\n",
    "        lat_step = (north - south) / grid_size\n",
    "        lon_step = (east - west) / grid_size\n",
    "        grid_queue = []\n",
    "\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                grid_south = south + i * lat_step\n",
    "                grid_north = south + (i + 1) * lat_step\n",
    "                grid_west = west + j * lon_step\n",
    "                grid_east = west + (j + 1) * lon_step\n",
    "                grid_queue.append((grid_south, grid_west, grid_north, grid_east, \n",
    "                                   num_to_letter(i) + num_to_letter(j)))\n",
    "\n",
    "        return grid_queue\n",
    "\n",
    "# Create a function to get the grid label of the coordinate point\n",
    "def get_grid_label(lat, lng, final_grids):\n",
    "    '''\n",
    "    lat         : latitude\n",
    "    lng         : longitude\n",
    "    final_grids : all cells and their minimum/maximum latitude/longitude\n",
    "    '''\n",
    "    for south, west, north, east, grid_label in final_grids:\n",
    "        if south <= lat <= north and west <= lng <= east:\n",
    "            return grid_label\n",
    "    return None\n",
    "\n",
    "def is_path_in_grid(south, west, north, east, path_points):\n",
    "        \"\"\"경로가 그리드 안에 있는지 확인\"\"\"\n",
    "        return any(south <= lat <= north and west <= lng <= east for lat, lng in path_points)\n",
    "\n",
    "def subdivide_grids(grid_queue, path_points):\n",
    "    \"\"\"그리드 분할\"\"\"\n",
    "    final_grids = []\n",
    "\n",
    "    while grid_queue:\n",
    "        south, west, north, east, grid_label = grid_queue.pop(0)\n",
    "        grid_size_km = min(geopy.distance.distance((south, west), (south, east)).km,\n",
    "                           geopy.distance.distance((south, west), (north, west)).km)\n",
    "            \n",
    "        if grid_size_km > min_size_km and is_path_in_grid(south, west, north, east, path_points):\n",
    "            mid_lat = (south + north) / 2\n",
    "            mid_lon = (west + east) / 2\n",
    "            grid_queue.append((south, west, mid_lat, mid_lon, grid_label + 'C'))\n",
    "            grid_queue.append((mid_lat, west, north, mid_lon, grid_label + 'A'))\n",
    "            grid_queue.append((south, mid_lon, mid_lat, east, grid_label + 'D'))\n",
    "            grid_queue.append((mid_lat, mid_lon, north, east, grid_label + 'B'))\n",
    "        else:\n",
    "            final_grids.append((south, west, north, east, grid_label))\n",
    "\n",
    "    return final_grids\n",
    "\n",
    "# Approximate border coordinates of South Korea\n",
    "south_korea_bounds = [33.10, 124.57, 38.60, 131]\n",
    "min_size_km = 0.76\n",
    "grid_size = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_grid</th>\n",
       "      <th>end_grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEACAADB</td>\n",
       "      <td>EGCADDDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EGCADDDC</td>\n",
       "      <td>GEACAADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEACAADA</td>\n",
       "      <td>GFACDBDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GFACDBDA</td>\n",
       "      <td>GFAADCDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GFAADCDC</td>\n",
       "      <td>GFACDCBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>GFACBABC</td>\n",
       "      <td>GFCADABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>GFCADABA</td>\n",
       "      <td>GECDBACA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>GECDBACA</td>\n",
       "      <td>GECCDDAB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>GECDCACC</td>\n",
       "      <td>GDDDDDAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>GDDDDDAB</td>\n",
       "      <td>GFCABACD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2609 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     start_grid  end_grid\n",
       "0      GEACAADB  EGCADDDC\n",
       "1      EGCADDDC  GEACAADA\n",
       "2      GEACAADA  GFACDBDA\n",
       "3      GFACDBDA  GFAADCDC\n",
       "4      GFAADCDC  GFACDCBA\n",
       "...         ...       ...\n",
       "2604   GFACBABC  GFCADABA\n",
       "2605   GFCADABA  GECDBACA\n",
       "2606   GECDBACA  GECCDDAB\n",
       "2607   GECDCACC  GDDDDDAA\n",
       "2608   GDDDDDAB  GFCABACD\n",
       "\n",
       "[2609 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터셋 로드\n",
    "#os.chdir('../')\n",
    "data_path=os.getcwd()+'/data/od_uuid/2023'\n",
    "\n",
    "#데이터셋 칼럼명 추가\n",
    "column_name=['id','start_time','end_time','start_lat','start_lng','end_lat','end_lng','?1','?2','?3']\n",
    "\n",
    "raw_data=pd.read_csv(data_path+'/00c02071a7d249b8b528230e9d63ad1d.csv')\n",
    "data=raw_data.values.tolist()\n",
    "dataframe=pd.DataFrame(data, columns=column_name)\n",
    "\n",
    "#전체데이터 그리드 생성\n",
    "start_points=dataframe[['start_lat','start_lng']].values.tolist()\n",
    "start_grid_queue = generate_initial_grids()\n",
    "start_final_grids = subdivide_grids(start_grid_queue, start_points)\n",
    "\n",
    "end_points=dataframe[['end_lat','end_lng']].values.tolist()\n",
    "end_grid_queue = generate_initial_grids()\n",
    "end_final_grids = subdivide_grids(end_grid_queue, end_points)\n",
    "\n",
    "dataframe['start_grid']=dataframe.apply(lambda row: get_grid_label(row['start_lat'], row['start_lng'], start_final_grids), axis=1)\n",
    "dataframe['end_grid']=dataframe.apply(lambda row: get_grid_label(row['end_lat'], row['end_lng'], end_final_grids), axis=1)\n",
    "dataframe=dataframe[['start_grid', 'end_grid']]\n",
    "dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 출력 데이터를 토크나이저로 변환\n",
    "tokenizer = Tokenizer(char_level=True)  # 문자 단위 토크나이저\n",
    "tokenizer.fit_on_texts(dataframe['start_grid'] + dataframe['end_grid'])  # 입력과 출력 데이터 모두에 적용\n",
    "\n",
    "# 문자열 -> 정수 시퀀스 변환\n",
    "input_sequences = tokenizer.texts_to_sequences(dataframe['start_grid'])\n",
    "output_sequences = tokenizer.texts_to_sequences(dataframe['end_grid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "num_classes = len(tokenizer.word_index) + 1  # 토큰 개수 +1 (0은 패딩에 사용)\n",
    "y_sequences = np.array([to_categorical(seq, num_classes=num_classes) for seq in output_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11\\anaconda3\\envs\\wedrive\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 훈련/테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.array(input_sequences), y_sequences, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 모델 생성\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=8),    #임베딩 레이어 \n",
    "    Bidirectional(LSTM(256, return_sequences=True)),\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),                                                                      #LSTM 레이어 \n",
    "    TimeDistributed(Dense(num_classes, activation='softmax'))                                                                         #Dense 레이어(출력층)\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.3891 - loss: 1.4607 - val_accuracy: 0.4859 - val_loss: 1.1846\n",
      "Epoch 2/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.5232 - loss: 1.1493 - val_accuracy: 0.5538 - val_loss: 1.0919\n",
      "Epoch 3/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.5510 - loss: 1.1001 - val_accuracy: 0.5502 - val_loss: 1.0753\n",
      "Epoch 4/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.5459 - loss: 1.1066 - val_accuracy: 0.5649 - val_loss: 1.0394\n",
      "Epoch 5/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.5845 - loss: 1.0287 - val_accuracy: 0.5499 - val_loss: 1.0600\n",
      "Epoch 6/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.5895 - loss: 1.0274 - val_accuracy: 0.5688 - val_loss: 1.0413\n",
      "Epoch 7/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.6044 - loss: 0.9860 - val_accuracy: 0.5703 - val_loss: 1.0287\n",
      "Epoch 8/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.6165 - loss: 0.9650 - val_accuracy: 0.5736 - val_loss: 1.0125\n",
      "Epoch 9/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.6104 - loss: 0.9694 - val_accuracy: 0.5781 - val_loss: 1.0082\n",
      "Epoch 10/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.6185 - loss: 0.9312 - val_accuracy: 0.5703 - val_loss: 1.0142\n",
      "Epoch 11/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.6261 - loss: 0.9260 - val_accuracy: 0.5682 - val_loss: 1.0210\n",
      "Epoch 12/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.6223 - loss: 0.9339 - val_accuracy: 0.5637 - val_loss: 1.0348\n",
      "Epoch 13/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.6345 - loss: 0.9203 - val_accuracy: 0.5634 - val_loss: 1.0125\n",
      "Epoch 14/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.6479 - loss: 0.8909 - val_accuracy: 0.5658 - val_loss: 1.0122\n",
      "Epoch 15/15\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.6404 - loss: 0.8844 - val_accuracy: 0.5757 - val_loss: 1.0003\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6076 - loss: 0.9620\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
      "----------------------------------------------\n",
      "Precision: 0.5683\n",
      "Recall: 0.5182\n",
      "F1-Score: 0.5333\n",
      "테스트 정확도: 0.6151819825172424\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=15, batch_size=4, validation_split=0.2)\n",
    "\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Precision, Recall, F1-Score 계산\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# One-Hot Encoded -> 정수 인코딩으로 변환\n",
    "y_test_flat = np.argmax(y_test, axis=-1).flatten()\n",
    "y_pred_flat = np.argmax(y_pred, axis=-1).flatten()\n",
    "precision = precision_score(y_test_flat, y_pred_flat, average=\"macro\")\n",
    "recall = recall_score(y_test_flat, y_pred_flat, average=\"macro\")\n",
    "f1 = f1_score(y_test_flat, y_pred_flat, average=\"macro\")\n",
    "\n",
    "print('----------------------------------------------')\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f'테스트 정확도: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "입력 텍스트: GFACBABC\n",
      "예측된 텍스트: GEACDADA\n"
     ]
    }
   ],
   "source": [
    "# 예측 수행\n",
    "example_text = 'GFACBABC'\n",
    "example_sequence = tokenizer.texts_to_sequences([example_text])[0]\n",
    "example_sequence = np.array([example_sequence])  # 모델 입력 형태로 변환\n",
    "\n",
    "# 예측 결과\n",
    "predictions = model.predict(example_sequence)\n",
    "predicted_tokens = np.argmax(predictions[0], axis=1)\n",
    "predicted_text = ''.join([tokenizer.index_word[token] for token in predicted_tokens])\n",
    "predicted_text=predicted_text.upper()\n",
    "print(f\"입력 텍스트: {example_text}\")\n",
    "print(f\"예측된 텍스트: {predicted_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GEACAADB\tEGCADDDC\n",
    "1\tEGCADDDC\tGEACAADA\n",
    "2\tGEACAADA\tGFACDBDA\n",
    "3\tGFACDBDA\tGFAADCDC\n",
    "4\tGFAADCDC\tGFACDCBA\n",
    "GFACBABC\tGFCADABA\n",
    "2605\tGFCADABA\tGECDBACA\n",
    "2606\tGECDBACA\tGECCDDAB\n",
    "2607\tGECDCACC\tGDDDDDAA\n",
    "2608\tGDDDDDAB\tGFCABACD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wedrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
